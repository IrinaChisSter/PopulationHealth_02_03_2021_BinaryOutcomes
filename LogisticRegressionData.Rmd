---
title: "LOGISTIC REGRESSION AND APPLICATIONS"  
author: "Dr Irina Chis Ster"
date: "21/01/2021"
output:
  html_notebook:  
    df_print: paged
editor_options:
  markdown:
    wrap: 72
---

## OUTLINE OF THE LECTURE

-   Continuous response/dependent variables - linear and multiple
    regression techniques

-   Binary response/dependent variable (e.g. presence/absence of
    disease)

-   Logistic regression - broadly similar set of techniques tailored to
    a different type of outcome (binary)

    -   it is also part of an array of so called generalized linear
        models given their resemblance with continuous case

-   The tale of a 2 by 2 table - scenarios and interpretations

-   Logistic regression used as a binary classifier - simple
    classification models

-   Sensitivity and specificity of a diagnosis test

-   Receiver operating characteristic curve (ROC) -the diagnostic
    ability of a binary classifier system as its discrimination
    threshold is varied

## LOGISTIC REGRESSION FRAMEWORK

-   Aims:

    -   to model the risk of a disease in a population, i.e. to
        investigate associations between the disease and the potential
        risk factors including exposures

    -   to understand patterns/heterogeneities associated with the
        occurrence of disease

-   Questions: what are the determinants or risk factors of a disease?

    -   Demographics?

    -   Environmental?

    -   Social?

-   Data needed:

    -   The outcome is a binary or dichotomous variable such as: yes/no,
        positive/ negative, presence/absence of disease.

    -   A series of potential explanatory variables which are
        hypothesized to be associated with the outcome

-   Assumptions:

    -   The outcome is assumed to be drawn from a binomial distribution
        with a parameter to be estimated from the data

    -   The observations are independent

    -   In case of a binary/categorical potential explanatory variable

        -   a case of a contingency table (such as two by two)

    -   In case of a continuous potential explanatory variable, the
        assumption is that there is a linear relationship between the
        [***logit of the outcome***]{.ul} and that potential predictor
        variable (rather than with the outcome directly) .

-   The logit function is $logit(\pi) = log(\frac{\pi}{1-\pi})$, where
    $\pi$ is the probabilities of the outcome

-   Under special and well organized epidemiological circumstances
    (design and the sample representation of the target population)
    $\pi$ is usually referred to as [***the risk***]{.ul} of the outcome
    (such as death) or the [***prevalence of the disease in that
    population***]{.ul} (if disease is the outcome)

-   Potential patterns of the outcome, i.e. its associations with groups
    in the population are understood by the odds ratios (ORs)

### REAL DATA EXAMPLE 1

-   These data are from the Mayo Clinic trial investigating primary
    biliary cirrhosis (PBC) of the liver conducted between 1974
    and 1984. A total of 424 PBC patients, referred to Mayo Clinic
    during that ten-year interval, met eligibility criteria for the
    randomized placebo controlled trial of the drug D-penicillamine. The
    first 312 cases in the data set participated in the randomized trial
    and contain largely complete data. The additional 112 cases did not
    participate in the clinical trial, but consented to have basic
    measurements recorded and to be followed for survival. Six of those
    cases were lost to follow-up shortly after diagnosis, so the data
    here are on an additional 106 cases as well as the 312 randomized
    participants. Details on the data are enclosed in the word document.
    The outcome is death/surviving and its association with the drug
    trial for those included in the trial but we will treat these data
    as an observational study and investigate the risk of death in PBC
    population in association with the available data.

### LOGISTIC REGRESSION ON A CATEGORICAL VARIABLE

-   A binary outcome and a binary/categorical potential association
-   Question is death more likely in men or women in this population?
-   Any familiarity?

```{r}
##reading the data in
mydata <-read.table("PBC_data_text_tab_sep.txt", header=T, sep="\t")
names(mydata)
dim(mydata)
summary(mydata)
```

#### A TWO BY TWO TABLE?

-   What about trying it ?

```{r}
table(mydata$sex) ##0=male, 1=female
table(mydata$status_bin) ## 0/1= alive/dead

mydata$sex<- mydata$sex+1
as.factor(mydata$sex)
mytable<-table(mydata$status_bin, mydata$sex)
mytable

margin.table(mytable, 1) # A frequencies (summed over B)
margin.table(mytable, 2) # B frequencies (summed over A)
prop.table(mytable) # cell percentages
prop.table(mytable, 1) # row percentages
prop.table(mytable, 2) # column percentages


epitable <- data.frame(Survived=c(17, 215),Died=c(27, 159))
rownames(epitable) <- c("Males","Female")
epitable
table2x2(epitable)
```

-   Main result to consider: The estimated odds ratio of death for women
    against men is 0.466 (CI95%: [0.245;0.884]). This means that women
    are almost twice less likely to die comparing to men in this cohort.

-   What about investigating this using a logistic regression?

```{r}
gender<-factor(mydata$sex)

logit_on_gender <- glm(mydata$status_bin~ gender, family = "binomial")

summary(logit_on_gender) 
exp(coef(logit_on_gender))
exp(cbind(OR = coef(logit_on_gender), confint(logit_on_gender)))


logit_all <- glm(mydata$status_bin~ 1, family = "binomial")
summary(logit_all) 
exp(coef(logit_all))
exp(cbind(OR = coef(logit_all), confint(logit_all)))

```

-   Main result to consider: The estimated odds ratio is 0.47
    (CI95%:[0.24;0.88])

-   If the 4 cells in the two by two table are filled with numbers of
    reasonable magnitude (\>=5), the two pieces of software should
    produce similar results.

-   The interpretation is then given in the study context.

-   For example, we would be tempted to say that death is lees likely in
    women than in men - but would that be the case? Remember the study
    design

### LOGISTIC REGRESSION ON A CONTINUOUS VARIABLE

-   We have dealt with a continuous and a categorical variable when the
    continuous variable was the dependent/response
-   What about the situation in which the binary (group variable)
    outcome is

```{r}
##fit the regression on age
mydata$age_years<-mydata$age/365.5
summary(mydata$age_years)
 
logit_on_age <- glm(status_bin ~age_years  , data = mydata, family = "binomial")
summary(logit_on_age)

##Hosmer-Lemeshow 
logitgof(mydata$status_bin, fitted(logit_on_age)  )

exp(coef(logit_on_age))
exp(cbind(OR = coef(logit_on_age), confint(logit_on_age)))

```

Interpretation:

-   The evidence suggests that OR of death increases with age in this
    PBC cohort (p=0.00746). One year increase in age increases the OR of
    death by a factor of 1.026(95%(1.007-1.045)). Or, one year increase
    in age increases the OR of death by 2.6%(0.7%-4.5%).

-   **The Hosmer-Lemeshow test** (p-value=0.27) for the goodness of fit
    is consistent with a good fit of the model to the data (a p-value
    less than 0.05 indicates a poor fit). The null hypothesis of the
    test states that the model is a good fit to the data.

### MULTIVARIABLE LOGISTIC REGRESSION

-   What about accounting for more than one variable?

```{r}
##fit the regression
mydata$sex_f<-as.factor(mydata$sex)
is.factor(mydata$sex_f)
table(mydata$sex_f)

logit_on_gender_age <- glm(status_bin~age_years +sex_f, data = mydata, family = "binomial")
summary(logit_on_gender_age)

##Hosmer-Lemeshow 
logitgof(mydata$status_bin, fitted(logit_on_gender_age)  )

exp(coef(logit_on_gender_age))
exp(cbind(OR = coef(logit_on_gender_age), confint(logit_on_gender_age)))

```

Interpretation:

-   The evidence suggests that, when controlling/adjusting for gender,
    the OR of death increases with age in this PBC cohort (p=0.00746).
    One year increase in age increases the adjusted (for gender) OR of
    death by a factor of 1.023(95%(1.004-1.043)). Or, one year increase
    in age increases the adjusted OR of death by 2.3%(0.4%-4.3%).

-   The estimated odds ratio of death for women against men is 0.523
    (CI95%: [0.268;0.995]). This means that women are almost twice less
    likely to die comparing to men in this cohort.

-   The Hosmer-Lemeshow test (p-value=0.07) for the goodness of fit is
    consistent with a good fit of the model to the data (a p-value less
    than 0.05 indicate a poor fit). The null hypothesis of the test
    states that the model is a good fit to the data.

### PREDICTIONS AFTER FITTING A MULTIVARIABLE MODEL

#### One continuous and one factor as independent variables

-   In essence, we would like to know what the model predicts, i.e. what
    is the risk of death with age by gender?

-   [***Additive model***]{.ul} - no interaction between age and gender.
    The assumption is that the risk of death varies with age at the same
    pace across the two groups defined by gender.

```{r}
##produce a spreasheed with values for ages within the data range
newdata1 <- with(mydata, data.frame( age_years = mean(age_years), sex_f = factor(1:2)))
newdata1


newdata1$sexP <- predict(logit_on_gender_age, newdata = newdata1, type = "response")
newdata1

newdata2 <- with(mydata, 
                 data.frame(age_years = rep(seq(from = 26 , to = 78 , 
                                                length.out = 100), 2),  
                            sex_f = factor(rep(1:2, each = 100))))

newdata3 <- cbind(newdata2, predict(logit_on_gender_age, newdata = newdata2, type = "link", se = TRUE))

newdata3 <- within(newdata3, {
    PredictedProb <- plogis(fit)
    LL <- plogis(fit - (1.96 * se.fit))
    UL <- plogis(fit + (1.96 * se.fit))
})

head(newdata3)

ggplot(newdata3, aes(x = age_years, y = PredictedProb)) + 
  geom_ribbon(aes(ymin = LL, ymax = UL, fill =sex_f), alpha = 0.2) + 
  geom_line(aes(colour =sex_f),size = 1)
 
```

-   The evidence suggests that, when controlling/adjusting for gender,
    the OR of death increases with age in this PBC cohort (p=0.00746).
    One year increase in age increases the adjusted (for gender) OR of
    death by a factor of 1.023(95%(1.004-1.043)). Or, one year increase
    in age increases the adjusted OR of death by 2.3%(0.4%-4.3%).
    [***The increase is irrespective of gender.***]{.ul}

<!-- -->

-   [***Multiplicative model***]{.ul} - testing a potential interaction
    between age and gender. in other words, we ask the question as to
    whether the risk of death varies with age similarly across the two
    gender groups or there is evidence that might not be the case?

```{r}
##the only modified bit from the doe above is the line below
logit_on_gender_age <- glm(status_bin ~age_years *sex_f, data = mydata, family = "binomial")
summary(logit_on_gender_age)

##Hosmer-Lemeshow 
logitgof(mydata$status_bin, fitted(logit_on_gender_age)  )

exp(coef(logit_on_gender_age))
exp(cbind(OR = coef(logit_on_gender_age), confint(logit_on_gender_age)))



newdata1 <- with(mydata, data.frame( age_years = mean(age_years), sex_f = factor(1:2)))
newdata1


newdata1$sexP <- predict(logit_on_gender_age, newdata = newdata1, type = "response")
newdata1

newdata2 <- with(mydata, data.frame(age_years = rep(seq(from = 26 , to = 78 , length.out = 100), 2),  sex_f = factor(rep(1:2, each = 100))))

newdata3 <- cbind(newdata2, predict(logit_on_gender_age, newdata = newdata2, type = "link", se = TRUE))

newdata3 <- within(newdata3, {
    PredictedProb <- plogis(fit)
    LL <- plogis(fit - (1.96 * se.fit))
    UL <- plogis(fit + (1.96 * se.fit))
})

head(newdata3)

ggplot(newdata3, aes(x = age_years, y = PredictedProb)) + geom_ribbon(aes(ymin = LL, ymax = UL, fill =sex_f), alpha = 0.2) + geom_line(aes(colour =sex_f),size = 1)

```

-   There is no evidence to suggest that the risk of death varies
    differently across the groups defined by gender.

#### Two factors as independent variables

-   [***Additive model***]{.ul} - no interaction between drug and
    gender. The assumption is that the OR of death for women vs. men is
    the same across groups defined by the drug. Or, equivalent, the OR
    of death for treatment vs. placebo is similar across groups defined
    by gender.

```{r}
#the only modified bit
table(mydata$drug)
mydata$drug_f<-factor(mydata$drug)

logit_on_gender_drug <- glm(status_bin ~ drug_f+sex_f, data = mydata, family = "binomial")
summary(logit_on_gender_drug)


exp(coef(logit_on_gender_drug))
exp(cbind(OR = coef(logit_on_gender_drug), confint(logit_on_gender_drug)))



newdata1 <- with(mydata, data.frame(drug_f = factor(1:2) , sex_f = factor(rep(1:2, each = 2))))
newdata1


newdata1$drug_genderP <- predict(logit_on_gender_drug, newdata = newdata1, type = "response")
newdata1

newdata2 <- with(mydata, data.frame(drug_f = factor(1:2) , sex_f = factor(rep(1:2, each = 2))))

newdata3 <- cbind(newdata2, predict(logit_on_gender_drug, newdata = newdata2, type = "link", se = TRUE))

newdata3 <- within(newdata3, {
    PredictedProb <- plogis(fit)
    LL <- plogis(fit - (1.96 * se.fit))
    UL <- plogis(fit + (1.96 * se.fit))
})

head(newdata3)

```

-   [***Multiplicative model***]{.ul} - no interaction between age and
    gender. The assumption is that the risk of death varies with age at
    the same pace across the two groups defined by gender.

```{r}
#the only modified bit

##drug 2=placebo, 1=intervention
table(mydata$drug)
mydata$drug_f<-factor(mydata$drug)

logit_on_gender_drug_inter <- glm(status_bin ~ drug_f*sex_f, data = mydata, family = "binomial")
summary(logit_on_gender_drug_inter)


exp(coef(logit_on_gender_drug_inter))
exp(cbind(OR = coef(logit_on_gender_drug_inter), confint(logit_on_gender_drug_inter)))



newdata1 <- with(mydata, data.frame(drug_f = factor(1:2) , sex_f = factor(rep(1:2, each = 2))))
newdata1


newdata1$drug_genderP <- predict(logit_on_gender_drug_inter, newdata = newdata1, type = "response")
newdata1

newdata2 <- with(mydata, data.frame(drug_f = factor(1:2) , sex_f = factor(rep(1:2, each = 2))))

newdata3 <- cbind(newdata2, predict(logit_on_gender_drug_inter, newdata = newdata2, type = "link", se = TRUE))

newdata3 <- within(newdata3, {
    PredictedProb <- plogis(fit)
    LL <- plogis(fit - (1.96 * se.fit))
    UL <- plogis(fit + (1.96 * se.fit))
})

head(newdata3)

```

### MODEL CHOICE and COMPARISON

-   AIC criterion

-   Likelihood ratio test

```{r}
AIC(logit_on_gender_drug, logit_on_gender_drug_inter)
lrtest(logit_on_gender_drug, logit_on_gender_drug_inter)
```

## THE TALE OF A TWO-BY-TWO TABLE

```{r}

GENERIC_TABLE <- data.frame(COL0=c("a", "c"),COL1=c("b","d"))
rownames(GENERIC_TABLE) <- c("ROW0","ROW1")
GENERIC_TABLE

```

-   From a statistical sampling perspective, there are only three ways
    to establish a 2 × 2 contingency table:

    -   the row margins (a + b) and (c + d) are fixed, in which case the
        column margins are observed and percentages can only be
        calculated horizontally;

    -   the column margins (a + c) and (b + d) are fixed, in which case
        the row margins are observed and percentages can only be
        calculated vertically;

    -   the grand total n is fixed, in which case all elements and
        margins of the table are observed and percentages can be
        calculated by row, by column, or globally.

-   Their analysis is strikingly simple

-   Nevertheless, when facing a 2 × 2 table, it is important to know how
    the the data were generated.

    -   independence of the observations

    -   study design (cross sectional, survey or case control study)

    -   their interpretation depends on the context

### Comparing Two Independent Proportions - 1

-   Smoking (No/Yes) was assessed in a sample of 1,262 high school boys
    and in a separate sample of 1,132 high school girls of the province
    of Luxembourg (data not published). Data are displayed by the
    routine below. In this table, column margins were fixed, and all
    other numbers were observed. Thus, percentages can only be derived
    vertically. The proportion of smokers among boys is 389/1,262
    (30.8%) and among girls 372/1,132 (32.9%). Are these two proportions
    statistically different?

```{r}

epitable <- data.frame(Boys=c(873, 389),Girls=c(730,372))
rownames(epitable) <- c("No","Yes")
epitable
table2x2(epitable)
```

-   INTERPRETATION: The data are consistent with no difference between
    the proportion of smokers among boys and girls (P\>0.05).

### Comparing Two Independent Proportions -2

-   Postoperative nausea (No/Yes) and vomiting (No/Yes) were recorded in
    671 surgical patients. Data are displayed by the routine below. In
    this table, only the grand total sample size *n* was fixed so that
    all other numbers were observed. Is there an association between
    nausea and vomiting? The null hypothesis of no association between
    the two symptoms can be assessed by the "independence test" by
    computing a chi-squared test similar to the homogeneity test above.

```{r}
epitable <- data.frame(Vomiting_no=c(532, 73),Vomiting_yes=c(13, 53))
rownames(epitable) <- c("Nausea_no","Nausea_yes")
epitable
table2x2(epitable)
```

-   INTERPRETATION: There is strong evidence against the null of no
    association between nausea and vomiting (P\<0.001).

### Comparing Two Paired (Matched) Proportions

-   In contrast to the homogeneity test, the McNemar test allows the
    comparison of two paired proportions obtained on the same subjects
    or on matched individuals. Data reported in the table below concern
    the distance walked (≤500 m or \>500 m) before and after surgery by
    156 patients suffering from degenerative lumbar stenosis with
    neurogenic intermittent claudication. In this table, the grand total
    *n* was fixed so that all other numbers in the table were observed.

```{r}
epitable <- data.frame(After_less500m=c(56, 20),After_more500m=c(37, 43))
rownames(epitable) <- c("Before_less500m","Before_more500m")
epitable
epimatrix<-matrix( c(56, 20, 37, 43),  nrow=2,  ncol=2) 
mcnemar.test(epimatrix)
##table2x2(epitable)

```

-   INTERPRETATION: There is some evidence against the null of no
    association between nausea and vomiting (P=0.03). This shows a
    significant difference between the two proportions. In other terms,
    the surgical treatment did change (improve) the walking distance of
    patients.

### Assessing the Degree of Agreement between Two Raters

The degree of agreement between two raters or methods can best be
measured by the Cohen kappa (κ) coefficient. As an illustration, data in
Table below were obtained by cross-classifying the diagnosis (benign or
malignant) of 187 suspected tumors made by 2D mammography and 3D
tomosynthesis. Readings were made by a senior radiologist. Once again,
the grand total n was fixed, and all numbers in the table were observed.

```{r}
epitable <- data.frame(Benign=c(54,14 ),Malignant=c(68,51))
rownames(epitable) <- c("Benign","Malignant")
epitable
##table2x2(epitable)

epimatrix = matrix( c(54,14,68,51),  nrow=2,  ncol=2) 
epimatrix
kappa(data=epimatrix)
mcnemar.test(epimatrix)
```

-   INTERPRETATION: The closer κ is to 1, the better the agreement
    between the two raters. The value of 0.19 is quite low, indicating
    poor agreement between the two diagnostic methods, hence confirming
    the highly significant McNemar test.

### Measuring the Diagnostic Value of a Clinical Test

-   In medical practice, assessing the diagnostic (prognostic) ability
    of a clinical (biological, radiological) test is often required.
    This is traditionally done by using concepts such as diagnostic
    specificity and sensitivity and positive (negative) predictive
    value. In this context, the row variable *X* is the clinical test
    (*T*) to be assessed (negative, positive) and the column variable
    *Y* the disease (*D*) to be diagnosed (absent, present). As an
    example, consider the Folin-Wu colorimetric test to assay blood
    glucose. Remein and Wilkerson applied this test to 510 presumably
    healthy subjects and to 70 diabetic patients. Data are given in
    Table below. In this table, column margins were fixed and all other
    numbers were observed. Thus, percentages can only be derived
    vertically.

```{r}
epitable <- data.frame(DiabetesNo=c(461, 49),DiabetesYes=c(14, 56))
rownames(epitable) <- c("TestNegative","TestPositive")
epitable
##table2x2(epitable)

dat <- as.table(matrix(c(461, 49,14, 56), nrow = 2, byrow = TRUE))
dat
epi.tests(dat, conf.level = 0.95)
 
```

### Measuring the association between an exposure and a Disease

A case control-study:looked at the association between diabetes (the
risk factor) and eye cataract (the disease) in 607 patients with
cataract and in 2,011 patients free of cataract.

```{r}
epitable <- data.frame(Cataract_yes=c(55, 552),Cataract_no=c(84, 927))
rownames(epitable) <- c("Diabetes_yes","Diabetes_no")
epitable
table2x2(epitable)

```

### Assessment of Binary Classifier with Visualization

```{r}
mydata_diabetes <-read.table("DiabetesData.txt", header=T, sep="\t")
names(mydata)
dim(mydata)
summary(mydata)

```

```{r}

logistic.model <- glm(as.factor(dtest)~chol+age+bmi, data = mydata_diabetes ,family = "binomial")
class <- logistic.model$y
score <- logistic.model$fitted.values

measure <- measureit(score = score, class = class, measure = c("ACC", "SENS", "FSCR"))
names(measure)

plot(measure$ACC~measure$Cutoff, type = "l")
plot(measure$ACC~measure$Cutoff, type = "l")

```

```{r}
logistic.model <- glm(as.factor(dtest)~ chol+age+bmi, data =mydata_diabetes, family = "binomial")

## make the score and class
class <- logistic.model$y
# score = log odds
score <- qlogis(logistic.model$fitted.values)

## rocit object
rocit_emp <- rocit(score = score, class = class, method = "emp")
rocit_bin <- rocit(score = score, class = class, method = "bin")
rocit_non <- rocit(score = score, class = class, method = "non")

summary(rocit_emp)
summary(rocit_bin)
summary(rocit_non)


plot(rocit_emp, col = c(1,"gray50"), legend = FALSE, YIndex = FALSE)
lines(rocit_bin$TPR~rocit_bin$FPR, col = 2, lwd = 2)
lines(rocit_non$TPR~rocit_non$FPR, col = 4, lwd = 2)
legend("bottomright", col = c(1,2,4), c("Empirical ROC", "Binormal ROC", "Non-parametric ROC"), lwd = 2)
```

## Area under the ROC curve -- assessing discrimination in logistic regression

```{r}
set.seed(34535)
n <- 1000
x <- rnorm(n)
pr <- exp(x)/(1+exp(x))
y <- 1*(runif(n) < pr)
mod <- glm(y~x, family="binomial")
predpr <- predict(mod,type=c("response"))
roccurve <- roc(y ~ predpr)
plot(roccurve)
```

```{r}
set.seed(34535)
n <- 1000
x <- rnorm(n)
pr <- exp(5*x)/(1+exp(5*x))
y <- 1*(runif(n) < pr)
mod <- glm(y~x, family="binomial")
predpr <- predict(mod,type=c("response"))
roccurve <- roc(y ~ predpr)
plot(roccurve)
```
